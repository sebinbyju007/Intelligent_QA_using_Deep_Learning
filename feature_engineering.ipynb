{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_engineering",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuyz38Dn5Ump",
        "outputId": "4ee9754d-65d4-4892-a0b7-a3bf7bc84a31"
      },
      "source": [
        "!pip install distance\n",
        "!pip install fuzzywuzzy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting distance\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/1a/883e47df323437aefa0d0a92ccfb38895d9416bd0b56262c2e46a47767b8/Distance-0.1.3.tar.gz (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 25.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 18.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 9.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 92kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 8.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-cp37-none-any.whl size=16261 sha256=7601472fac4b81a4c351a3bea6c02cccc637fa9fee1b0ed7bd6b22b777d792a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/aa/e1/dbba9e7b6d397d645d0f12db1c66dbae9c5442b39b001db18e\n",
            "Successfully built distance\n",
            "Installing collected packages: distance\n",
            "Successfully installed distance-0.1.3\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mbiKGqyr3fLU",
        "outputId": "070aefdb-143f-446e-981c-7d1b34ad3c10"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import distance\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import distance\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from fuzzywuzzy import fuzz\n",
        "from sklearn.manifold import TSNE\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from os import path\n",
        "from PIL import Image"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "9ebQzpmn5eHc",
        "outputId": "80691d39-2f48-43a2-e76e-ab91903bf48f"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Project/train.csv.zip')\n",
        "df.head(8)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "5   5    11  ...  I'm a triple Capricorn (Sun, Moon and ascendan...            1\n",
              "6   6    13  ...  What keeps childern active and far from phone ...            0\n",
              "7   7    15  ...          What should I do to be a great geologist?            1\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ojeRvY5rAR",
        "outputId": "2fa05efe-9e1d-4090-99ae-50e6a9e521aa"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 404290 entries, 0 to 404289\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   id            404290 non-null  int64 \n",
            " 1   qid1          404290 non-null  int64 \n",
            " 2   qid2          404290 non-null  int64 \n",
            " 3   question1     404289 non-null  object\n",
            " 4   question2     404288 non-null  object\n",
            " 5   is_duplicate  404290 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 18.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "07FnUY5m5t5N",
        "outputId": "e501497b-df77-48ce-9ee0-b74855bb54a6"
      },
      "source": [
        "print( round(df['is_duplicate'].mean()*100, 2),\"% duplicated question pairs.\")\n",
        "print(100- round(df['is_duplicate'].mean()*100, 2),\"% non duplicated question pairs.\")\n",
        "df.groupby(\"is_duplicate\")['id'].count().plot.bar()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36.92 % duplicated question pairs.\n",
            "63.08 % non duplicated question pairs.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f25eb58fc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idVppuJyDPYr"
      },
      "source": [
        "df = df.fillna('')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ItJlpDD9Tsi"
      },
      "source": [
        "## Feature Enginerring \n",
        "\n",
        " - ___q1len___ = Length of q1\n",
        " - ___q2len___ = Length of q2\n",
        " - ___diff_len___ = len(q1)-len(q2)       \n",
        "\n",
        "\n",
        " - ___q1_n_words___ = Number of words in q1\n",
        " - ___q2_n_words___ = Number of words in q2\n",
        " - ___diff_n_words___ = The difference       \n",
        "\n",
        "\n",
        " - ___caps_count_q1___ = Number of capital words of q1\n",
        " - ___caps_count_q2___ = Number of capital words of q2\n",
        " - ___diff_caps___ = The difference       \n",
        "\n",
        "\n",
        " - ___len_char_q1___ = Number of characters of q1\n",
        " - ___len_char_q2___ = Number of characters of q2\n",
        " - ___diff_len_char___ = The difference      \n",
        "\n",
        "\n",
        " - ___avg_word_len1___ = len(char)/len(word) of q1\n",
        " - ___avg_word_len2___ = len(char)/len(word) of q2\n",
        " - ___diff_avg_word___ = The difference      \n",
        "\n",
        "\n",
        " - ___word_Common___ = Number of common unique words in q1 and q2\n",
        " - ___word_Total___ = Total num of words in Question 1 + Total num of words in q2\n",
        " - ___word_share___ = (word_common)/(word_Total)    \n",
        " - ___2_gram_share___ = word share on 2 gram\n",
        "\n",
        "\n",
        " - ___exactly_same___ = exactly the same\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "Ktl-pQga7R9O",
        "outputId": "4ced38f2-7514-4f07-8b65-eaf4562b3bc4"
      },
      "source": [
        "if os.path.isfile('/content/drive/MyDrive/Project/feature_tm.csv'):\n",
        "  df = pd.read_csv('/content/drive/MyDrive/Project/feature_tm.csv',encoding='latin-1')\n",
        "else:\n",
        "  df['q1len'] = df.question1.str.len()\n",
        "  df['q2len'] = df.question2.str.len()\n",
        "  df['diff_len'] = df.q1len - df.q2len\n",
        "  \n",
        "  df['len_word_q1'] = df.question1.apply(lambda row: len(row.split(\" \")))\n",
        "  df['len_word_q2'] = df.question2.apply(lambda row: len(row.split(\" \")))\n",
        "  df['diff_words'] = df.len_word_q1 - df.len_word_q2\n",
        "  \n",
        "  df['caps_count_q1'] = df.question1.apply(lambda x:sum(1 for i in str(x) if i.isupper()))\n",
        "  df['caps_count_q2'] = df.question2.apply(lambda x:sum(1 for i in str(x) if i.isupper()))\n",
        "  df['diff_caps'] = df.caps_count_q1 - df.caps_count_q2\n",
        "  \n",
        "  df['len_char_q1'] = df.question1.apply(lambda x: len(str(x).replace(' ', '')))\n",
        "  df['len_char_q2'] = df.question2.apply(lambda x: len(str(x).replace(' ', '')))\n",
        "  df['diff_len_char'] = df.len_char_q1 - df.len_char_q2\n",
        "  \n",
        "  df['avg_world_len1'] = df.len_char_q1 / df.len_word_q1\n",
        "  df['avg_world_len2'] = df.len_char_q2 / df.len_word_q2\n",
        "  df['diff_avg_word'] = df.avg_world_len1 - df.avg_world_len2\n",
        "\n",
        "  def word_common(row):\n",
        "      w1 = set(map(lambda word: word.lower().strip(), row.question1.split(\" \")))\n",
        "      w2 = set(map(lambda word: word.lower().strip(), row.question2.split(\" \")))    \n",
        "      return 1.0 * len(w1 & w2)\n",
        "\n",
        "  def word_total(row):\n",
        "      w1 = set(map(lambda word: word.lower().strip(), row.question1.split(\" \")))\n",
        "      w2 = set(map(lambda word: word.lower().strip(), row.question2.split(\" \")))    \n",
        "      return 1.0 * (len(w1) + len(w2))\n",
        "\n",
        "  def word_share(row):\n",
        "      w1 = set(map(lambda word: word.lower().strip(), row.question1.split(\" \")))\n",
        "      w2 = set(map(lambda word: word.lower().strip(), row.question2.split(\" \")))    \n",
        "      return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
        "\n",
        "  def get_2_gram_share(row):\n",
        "      q1_list = str(row.question1).lower().split()\n",
        "      q2_list = str(row.question2).lower().split()\n",
        "      q1_2_gram = set([i for i in zip(q1_list, q1_list[1:])])\n",
        "      q2_2_gram = set([i for i in zip(q2_list, q2_list[1:])])\n",
        "      shared_2_gram = q1_2_gram.intersection(q2_2_gram)\n",
        "      if len(q1_2_gram) + len(q2_2_gram) == 0:\n",
        "          R2gram = 0\n",
        "      else:\n",
        "          R2gram = len(shared_2_gram) / (len(q1_2_gram) + len(q2_2_gram))\n",
        "      return R2gram\n",
        "\n",
        "  df['word_Common'] = df.apply(word_common, axis=1)\n",
        "  df['word_Total'] = df.apply(word_total, axis=1)\n",
        "  df['word_share'] = df.apply(word_share, axis=1)\n",
        "  df['share_2_gram'] = df.apply(get_2_gram_share, axis=1) \n",
        "\n",
        "  df.to_csv('/content/drive/MyDrive/Project/feature_tm.csv', index=False)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>q1len</th>\n",
              "      <th>q2len</th>\n",
              "      <th>diff_len</th>\n",
              "      <th>len_word_q1</th>\n",
              "      <th>len_word_q2</th>\n",
              "      <th>diff_words</th>\n",
              "      <th>caps_count_q1</th>\n",
              "      <th>caps_count_q2</th>\n",
              "      <th>diff_caps</th>\n",
              "      <th>len_char_q1</th>\n",
              "      <th>len_char_q2</th>\n",
              "      <th>diff_len_char</th>\n",
              "      <th>avg_world_len1</th>\n",
              "      <th>avg_world_len2</th>\n",
              "      <th>diff_avg_word</th>\n",
              "      <th>word_Common</th>\n",
              "      <th>word_Total</th>\n",
              "      <th>word_share</th>\n",
              "      <th>share_2_gram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>3.785714</td>\n",
              "      <td>3.833333</td>\n",
              "      <td>-0.047619</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.416667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>-37</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>-5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>76</td>\n",
              "      <td>-32</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>5.846154</td>\n",
              "      <td>-0.346154</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.052632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>59</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>4.285714</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>-0.714286</td>\n",
              "      <td>4.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.045455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>-15</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>40</td>\n",
              "      <td>57</td>\n",
              "      <td>-17</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>6.333333</td>\n",
              "      <td>-2.696970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>39</td>\n",
              "      <td>37</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>33</td>\n",
              "      <td>31</td>\n",
              "      <td>4.923077</td>\n",
              "      <td>4.714286</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2  ... word_Total word_share  share_2_gram\n",
              "0   0     1     2  ...       23.0   0.434783      0.416667\n",
              "1   1     3     4  ...       20.0   0.200000      0.052632\n",
              "2   2     5     6  ...       24.0   0.166667      0.045455\n",
              "3   3     7     8  ...       19.0   0.000000      0.000000\n",
              "4   4     9    10  ...       20.0   0.100000      0.000000\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVkRmv7rkXGa"
      },
      "source": [
        "## Feature Engineering on NLP Features\n",
        "- __last_word_eq__ :  Check if Last word of both questions is equal or not<br>\n",
        "\n",
        "\n",
        "- __first_word_eq__ :  Check if First word of both questions is equal or not<br>\n",
        "\n",
        "\n",
        "- __abs_len_diff__ :  Abs. length difference<br>\n",
        "\n",
        "\n",
        "- __mean_len__ :  Average Token Length of both Questions<br>\n",
        "\n",
        "- __cwc_min__ :  Ratio of common_word_count to min lenghth of word count of Q1 and Q2 <br>\n",
        "\n",
        "\n",
        "- __cwc_max__ :  Ratio of common_word_count to max lenghth of word count of Q1 and Q2 <br>\n",
        "\n",
        "- __csc_min__ :  Ratio of common_stop_count to min lenghth of stop count of Q1 and Q2 <br>\n",
        "\n",
        "\n",
        "- __csc_max__ :  Ratio of common_stop_count to max lenghth of stop count of Q1 and Q2<br>\n",
        "\n",
        "- __ctc_min__ :  Ratio of common_token_count to min lenghth of token count of Q1 and Q2<br>\n",
        "\n",
        "\n",
        "- __ctc_max__ :  Ratio of common_token_count to max lenghth of token count of Q1 and Q2<br>\n",
        "\n",
        "- __wmd_dist__:\n",
        "- __cosine_dist__\n",
        "\n",
        "- __cityblock_dist__\n",
        "\n",
        "\n",
        "- __canberra_dist__\n",
        "\n",
        "- __euclidean_dist__\n",
        "\n",
        "\n",
        "- __minkowski_dist__\n",
        "\n",
        "\n",
        "- __fuzz_ratio__ \n",
        "\n",
        "- __fuzz_partial_ratio__\n",
        "\n",
        "\n",
        "- __token_sort_ratio__\n",
        "\n",
        "\n",
        "- __token_set_ratio__ \n",
        "\n",
        "\n",
        "- __longest_substr_ratio__ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuGOD6NXk_-m",
        "outputId": "660e7352-17f5-4cf1-98c0-8f5e93be8ace"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "SAFE_DIV = 0.0001 \n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "STOP_WORDS = stopwords.words('english')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96TXv7DUlcyC"
      },
      "source": [
        "def preprocess(x):\n",
        "    x = str(x).lower()\n",
        "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
        "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
        "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
        "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
        "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
        "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
        "    \n",
        "    \n",
        "    porter = PorterStemmer()\n",
        "    pattern = re.compile('\\W')\n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = re.sub(pattern, ' ', x)\n",
        "    \n",
        "    \n",
        "    if type(x) == type(''):\n",
        "        x = porter.stem(x)\n",
        "        example1 = BeautifulSoup(x)\n",
        "        x = example1.get_text()\n",
        "               \n",
        "    \n",
        "    return x\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXTVQSUwlhDL"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "import gensim\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nft3-1KalqvI"
      },
      "source": [
        "glove2word2vec(glove_input_file=\"/content/drive/MyDrive/Project/glove.840B.300d.txt\", word2vec_output_file=\"glove_vectors.txt\")\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"glove_vectors.txt\", binary=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skd1W5Awl5_L"
      },
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.spatial.distance import cosine, cityblock, canberra, euclidean, minkowski"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWuFKnAem9pk"
      },
      "source": [
        "def remove_stop(sentence):\n",
        "    sentence  = str(sentence)\n",
        "    if sentence == None:\n",
        "        return ' '\n",
        "    if sentence == np.nan:\n",
        "        return ' '\n",
        "    if sentence == 'NaN':\n",
        "        return ' '\n",
        "    z = [i for i in sentence.split() if i not in STOP_WORDS]\n",
        "    return ' '.join(z)\n",
        "  \n",
        "def wmd(s1, s2, model):\n",
        "    s1 = str(s1)\n",
        "    s2 = str(s2)\n",
        "    s1 = s1.split()\n",
        "    s2 = s2.split()\n",
        "    return model.wmdistance(s1, s2)\n",
        "\n",
        "def g2w2v(list_of_sent, model, d):\n",
        "    sent_vectors = []\n",
        "    for sentence in list_of_sent: \n",
        "        doc = [word for word in sentence if word in model.wv.vocab] \n",
        "        if doc:\n",
        "            sent_vec = np.mean(model.wv[doc],axis=0) \n",
        "        else:\n",
        "            sent_vec = np.zeros(d)\n",
        "        sent_vectors.append(sent_vec)\n",
        "    return sent_vectors\n",
        "\n",
        "def get_distance_features(df):\n",
        "    \n",
        "    print(\"Extracting Distance Features..\")\n",
        "    \n",
        "    df['question1'] = df.question1.apply(remove_stop)\n",
        "    df['question2'] = df.question2.apply(remove_stop)\n",
        "    df['word_mover_dist'] = df.apply(lambda x: wmd(x['question1'], x['question2'],glove_model), axis=1)\n",
        "    \n",
        "    print(\"- wmd done...\")\n",
        "    \n",
        "    list_of_question1=[]\n",
        "    for sentence in df.question1.values:\n",
        "        list_of_question1.append(sentence.split())\n",
        "    \n",
        "    list_of_question2=[]\n",
        "    for sentence in df.question2.values:\n",
        "        list_of_question2.append(sentence.split())\n",
        "    \n",
        "    g2w2v_q1 = g2w2v(list_of_question1, glove_model, 300)\n",
        "    g2w2v_q2 = g2w2v(list_of_question2, glove_model, 300)\n",
        "    \n",
        "    print(\"- embedding done...\")\n",
        "    \n",
        "    df['cosine_dist'] = [cosine(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['cityblock_dist'] = [cityblock(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['canberra_dist'] = [canberra(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['euclidean_dist'] = [euclidean(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    df['minkowski_dist'] = [minkowski(q1, q2) for (q1, q2) in zip(g2w2v_q1,g2w2v_q2)]\n",
        "    \n",
        "    print('- spatial distance done')\n",
        "    \n",
        "    df.cosine_dist = df.cosine_dist.fillna(0)\n",
        "    df.word_mover_dist = df.word_mover_dist.apply(lambda wmd: 30 if wmd == np.inf else wmd )\n",
        "   \n",
        "    return df"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ciXohKen137"
      },
      "source": [
        "def get_token_features(q1, q2):\n",
        "    token_features = [0.0]*10\n",
        "    \n",
        "    q1_tokens = q1.split()\n",
        "    q2_tokens = q2.split()\n",
        "\n",
        "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
        "        return token_features\n",
        "    \n",
        "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
        "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
        "    \n",
        "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
        "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
        "    \n",
        "    common_word_count = len(q1_words.intersection(q2_words))\n",
        "    \n",
        "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
        "    \n",
        "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
        "    \n",
        "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
        "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
        "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
        "    \n",
        "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
        "    \n",
        "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
        "    \n",
        "    token_features[8] = abs(len(q1_tokens) - len(q2_tokens))\n",
        "    \n",
        "    token_features[9] = (len(q1_tokens) + len(q2_tokens))/2\n",
        "    return token_features\n",
        "\n",
        "\n",
        "def get_longest_substr_ratio(a, b):\n",
        "    strs = list(distance.lcsubstrings(a, b))\n",
        "    if len(strs) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return len(strs[0]) / (min(len(a), len(b)) + 1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2CoDlSuofXg"
      },
      "source": [
        "def extract_features(df):\n",
        "    df[\"question1\"] = df[\"question1\"].fillna(\"\").apply(preprocess)\n",
        "    df[\"question2\"] = df[\"question2\"].fillna(\"\").apply(preprocess)\n",
        "\n",
        "    print(\"Extracting Token Features...\")\n",
        "    \n",
        "    token_features = df.apply(lambda x: get_token_features(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    \n",
        "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
        "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
        "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
        "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
        "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
        "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
        "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
        "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
        "    df[\"abs_len_diff\"]  = list(map(lambda x: x[8], token_features))\n",
        "    df[\"mean_len\"]      = list(map(lambda x: x[9], token_features))\n",
        "   \n",
        "    print(\"Extracting Fuzzy Features..\")\n",
        "\n",
        "    df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_ratio\"]            = df.apply(lambda x: fuzz.QRatio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    df[\"longest_substr_ratio\"]  = df.apply(lambda x: get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "    return df"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "CodJdJkfolgZ",
        "outputId": "54c0949b-3fdb-48fb-b22d-631551e2c540"
      },
      "source": [
        "if os.path.isfile('feature_nlp.csv'):\n",
        "    df_nlp = pd.read_csv(\"feature_nlp.csv\",encoding='latin-1')\n",
        "else:\n",
        "    print(\"Extracting features for train:\")\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Project/train.csv.zip\")\n",
        "    df = extract_features(df)\n",
        "    df = get_distance_features(df)\n",
        "    df = df.drop(['qid1','qid2','question1','question2','is_duplicate'], axis=1)\n",
        "    df.to_csv(\"feature_nlp.csv\", index=False)\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting features for train:\n",
            "Extracting Token Features...\n",
            "Extracting Fuzzy Features..\n",
            "Extracting Distance Features..\n",
            "- wmd done...\n",
            "- embedding done...\n",
            "- spatial distance done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cwc_min</th>\n",
              "      <th>cwc_max</th>\n",
              "      <th>csc_min</th>\n",
              "      <th>csc_max</th>\n",
              "      <th>ctc_min</th>\n",
              "      <th>ctc_max</th>\n",
              "      <th>last_word_eq</th>\n",
              "      <th>first_word_eq</th>\n",
              "      <th>abs_len_diff</th>\n",
              "      <th>mean_len</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>fuzz_ratio</th>\n",
              "      <th>fuzz_partial_ratio</th>\n",
              "      <th>longest_substr_ratio</th>\n",
              "      <th>word_mover_dist</th>\n",
              "      <th>cosine_dist</th>\n",
              "      <th>cityblock_dist</th>\n",
              "      <th>canberra_dist</th>\n",
              "      <th>euclidean_dist</th>\n",
              "      <th>minkowski_dist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999980</td>\n",
              "      <td>0.833319</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.916659</td>\n",
              "      <td>0.785709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>100</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>100</td>\n",
              "      <td>0.982759</td>\n",
              "      <td>1.216034</td>\n",
              "      <td>0.031762</td>\n",
              "      <td>14.274065</td>\n",
              "      <td>91.483062</td>\n",
              "      <td>1.047253</td>\n",
              "      <td>1.047253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.799984</td>\n",
              "      <td>0.399996</td>\n",
              "      <td>0.749981</td>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.699993</td>\n",
              "      <td>0.466664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>86</td>\n",
              "      <td>63</td>\n",
              "      <td>66</td>\n",
              "      <td>75</td>\n",
              "      <td>0.596154</td>\n",
              "      <td>4.897662</td>\n",
              "      <td>0.266555</td>\n",
              "      <td>33.272633</td>\n",
              "      <td>149.670092</td>\n",
              "      <td>2.624989</td>\n",
              "      <td>2.624989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.399992</td>\n",
              "      <td>0.333328</td>\n",
              "      <td>0.399992</td>\n",
              "      <td>0.249997</td>\n",
              "      <td>0.399996</td>\n",
              "      <td>0.285712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>43</td>\n",
              "      <td>47</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>4.011556</td>\n",
              "      <td>0.118900</td>\n",
              "      <td>28.457512</td>\n",
              "      <td>129.214660</td>\n",
              "      <td>2.140298</td>\n",
              "      <td>2.140298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>28</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>7.514702</td>\n",
              "      <td>0.619671</td>\n",
              "      <td>62.016426</td>\n",
              "      <td>200.899534</td>\n",
              "      <td>4.702347</td>\n",
              "      <td>4.702347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.399992</td>\n",
              "      <td>0.199998</td>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.666644</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.307690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>67</td>\n",
              "      <td>47</td>\n",
              "      <td>35</td>\n",
              "      <td>56</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>6.257260</td>\n",
              "      <td>0.244168</td>\n",
              "      <td>40.127296</td>\n",
              "      <td>156.627744</td>\n",
              "      <td>3.145122</td>\n",
              "      <td>3.145122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id   cwc_min   cwc_max  ...  canberra_dist  euclidean_dist  minkowski_dist\n",
              "0   0  0.999980  0.833319  ...      91.483062        1.047253        1.047253\n",
              "1   1  0.799984  0.399996  ...     149.670092        2.624989        2.624989\n",
              "2   2  0.399992  0.333328  ...     129.214660        2.140298        2.140298\n",
              "3   3  0.000000  0.000000  ...     200.899534        4.702347        4.702347\n",
              "4   4  0.399992  0.199998  ...     156.627744        3.145122        3.145122\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg9Wsup6pHHd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}